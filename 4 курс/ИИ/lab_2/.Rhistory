# Преобразуем метки классов в фактор
train_data$Color <- as.factor(train_data$Color)
test_data$Color <- as.factor(test_data$Color)
# Построение модели SVM с ядром "linear" и C=1
svm_model <- svm(Color ~ X1 + X2, data = train_data, kernel = "linear", cost = 1)
# Вывод информации о модели
summary(svm_model)
# 1) Визуализация разбиения пространства признаков на области
# Генерируем сетку для предсказания
grid <- expand.grid(X1 = seq(min(train_data$X1), max(train_data$X1), length = 200),
X2 = seq(min(train_data$X2), max(train_data$X2), length = 200))
# Прогнозирование на сетке
predictions <- predict(svm_model, newdata = grid)
# Создаем график с использованием ggplot2
plot <- ggplot(train_data, aes(x = X1, y = X2)) +
geom_point(aes(color = Color)) +
geom_raster(data = grid, aes(x = X1, y = X2, fill = predictions), interpolate = TRUE, alpha = 0.3) +
scale_fill_manual(values = c("red" = "-1", "green" = "1"), name = "Класс") +
scale_color_manual(values = c("brown" = "-1", "black" = "1"), name = "Класс из файла") +
theme_minimal() +
labs(title = "SVM с линейным ядром",
x = "X1", y = "X2")
# Отображаем график
print(plot)
# Загрузка необходимых пакетов
library(e1071)
library(ggplot2)
# Загрузка данных из файлов
train_data <- read.table("./svmdata1.txt", header = TRUE)
test_data <- read.table("./svmdata1test.txt", header = TRUE)
# Преобразуем метки классов в фактор
train_data$Color <- as.factor(train_data$Color)
test_data$Color <- as.factor(test_data$Color)
# Построение модели SVM с ядром "linear" и C=1
svm_model <- svm(Color ~ X1 + X2, data = train_data, kernel = "linear", cost = 1)
# Вывод информации о модели
summary(svm_model)
# 1) Визуализация разбиения пространства признаков на области
# Генерируем сетку для предсказания
grid <- expand.grid(X1 = seq(min(train_data$X1), max(train_data$X1), length = 200),
X2 = seq(min(train_data$X2), max(train_data$X2), length = 200))
# Прогнозирование на сетке
predictions <- predict(svm_model, newdata = grid)
# Создаем график с использованием ggplot2
plot <- ggplot(train_data, aes(x = X1, y = X2)) +
geom_point(aes(color = Color)) +
geom_raster(data = grid, aes(x = X1, y = X2, fill = predictions), interpolate = TRUE, alpha = 0.3) +
scale_fill_manual(values = c("red" = "-1", "green" = "1"), name = "Класс") +
scale_color_manual(values = c("red" = "brown", "green" = "black"), name = "Класс из файла") +
theme_minimal() +
labs(title = "SVM с линейным ядром",
x = "X1", y = "X2")
# Отображаем график
print(plot)
# Загрузка необходимых пакетов
library(e1071)
library(ggplot2)
# Загрузка данных из файлов
train_data <- read.table("./svmdata1.txt", header = TRUE)
test_data <- read.table("./svmdata1test.txt", header = TRUE)
# Преобразуем метки классов в фактор
train_data$Color <- as.factor(train_data$Color)
test_data$Color <- as.factor(test_data$Color)
# Построение модели SVM с ядром "linear" и C=1
svm_model <- svm(Color ~ X1 + X2, data = train_data, kernel = "linear", cost = 1)
# Вывод информации о модели
summary(svm_model)
# 1) Визуализация разбиения пространства признаков на области
# Генерируем сетку для предсказания
grid <- expand.grid(X1 = seq(min(train_data$X1), max(train_data$X1), length = 200),
X2 = seq(min(train_data$X2), max(train_data$X2), length = 200))
# Прогнозирование на сетке
predictions <- predict(svm_model, newdata = grid)
# Создаем график с использованием ggplot2
plot <- ggplot(train_data, aes(x = X1, y = X2)) +
geom_point(aes(color = Color)) +
geom_raster(data = grid, aes(x = X1, y = X2, fill = predictions), interpolate = TRUE, alpha = 0.3) +
scale_fill_manual(values = c("red" = "-1", "green" = "1"), name = "Класс") +
scale_color_manual(values = c("red" = "red", "green" = "green"), name = "Класс из файла") +
theme_minimal() +
labs(title = "SVM с линейным ядром",
x = "X1", y = "X2")
# Отображаем график
print(plot)
# Загрузка необходимых пакетов
library(e1071)
library(ggplot2)
# Загрузка данных из файлов
train_data <- read.table("./svmdata1.txt", header = TRUE)
test_data <- read.table("./svmdata1test.txt", header = TRUE)
# Преобразуем метки классов в фактор
train_data$Color <- as.factor(train_data$Color)
test_data$Color <- as.factor(test_data$Color)
# Построение модели SVM с ядром "linear" и C=1
svm_model <- svm(Color ~ X1 + X2, data = train_data, kernel = "linear", cost = 1)
# Вывод информации о модели
summary(svm_model)
# 1) Визуализация разбиения пространства признаков на области
# Генерируем сетку для предсказания
grid <- expand.grid(X1 = seq(min(train_data$X1), max(train_data$X1), length = 200),
X2 = seq(min(train_data$X2), max(train_data$X2), length = 200))
# Прогнозирование на сетке
predictions <- predict(svm_model, newdata = grid)
# Создаем график с использованием ggplot2
plot <- ggplot(train_data, aes(x = X1, y = X2)) +
geom_point(aes(color = Color)) +
geom_raster(data = grid, aes(x = X1, y = X2, fill = predictions), interpolate = TRUE, alpha = 0.3) +
scale_fill_manual(values = c("-1" = "red", "1" = "green"), name = "Класс") +
scale_color_manual(values = c("red" = "red", "green" = "green"), name = "Класс из файла") +
theme_minimal() +
labs(title = "SVM с линейным ядром",
x = "X1", y = "X2")
# Отображаем график
print(plot)
# Печатаем количество опорных векторов
cat("Количество опорных векторов:", nrow(svm_model$SV), "\n")
# Загрузка необходимых пакетов
library(e1071)
library(ggplot2)
# Загрузка данных из файлов
train_data <- read.table("./svmdata1.txt", header = TRUE)
test_data <- read.table("./svmdata1test.txt", header = TRUE)
# Преобразуем метки классов в фактор
train_data$Color <- as.factor(train_data$Color)
test_data$Color <- as.factor(test_data$Color)
# Построение модели SVM с ядром "linear" и C=1
svm_model <- svm(Color ~ X1 + X2, data = train_data, kernel = "linear", cost = 1)
# Вывод информации о модели
summary(svm_model)
# 1) Визуализация разбиения пространства признаков на области
# Генерируем сетку для предсказания
grid <- expand.grid(X1 = seq(min(train_data$X1), max(train_data$X1), length = 200),
X2 = seq(min(train_data$X2), max(train_data$X2), length = 200))
# Прогнозирование на сетке
predictions <- predict(svm_model, newdata = grid)
# Создаем график с использованием ggplot2
plot <- ggplot(train_data, aes(x = X1, y = X2)) +
geom_point(aes(color = Color)) +
geom_raster(data = grid, aes(x = X1, y = X2, fill = predictions), interpolate = TRUE, alpha = 0.3) +
scale_fill_manual(values = c("red" = "red", "green" = "green"), name = "Класс") +
scale_color_manual(values = c("red" = "red", "green" = "green"), name = "Класс из файла") +
theme_minimal() +
labs(title = "SVM с линейным ядром",
x = "X1", y = "X2")
# Отображаем график
print(plot)
# Печатаем количество опорных векторов
cat("Количество опорных векторов:", nrow(svm_model$SV), "\n")
# Загрузка необходимых пакетов
library(e1071)
library(ggplot2)
# Загрузка данных из файлов
train_data <- read.table("./svmdata1.txt", header = TRUE)
test_data <- read.table("./svmdata1test.txt", header = TRUE)
# Преобразуем метки классов в фактор
train_data$Color <- as.factor(train_data$Color)
test_data$Color <- as.factor(test_data$Color)
# Построение модели SVM с ядром "linear" и C=1
svm_model <- svm(Color ~ X1 + X2, data = train_data, kernel = "linear", cost = 1)
# Вывод информации о модели
summary(svm_model)
# 1) Визуализация разбиения пространства признаков на области
# Генерируем сетку для предсказания
grid <- expand.grid(X1 = seq(min(train_data$X1), max(train_data$X1), length = 200),
X2 = seq(min(train_data$X2), max(train_data$X2), length = 200))
# Прогнозирование на сетке
predictions <- predict(svm_model, newdata = grid)
# Создаем график с использованием ggplot2
plot <- ggplot(train_data, aes(x = X1, y = X2)) +
geom_point(aes(color = Color)) +
geom_raster(data = grid, aes(x = X1, y = X2, fill = predictions), interpolate = TRUE, alpha = 0.3) +
scale_fill_manual(values = c("red" = "red", "green" = "green"), name = "Класс") +
scale_color_manual(values = c("red" = "red", "black" = "green"), name = "Класс из файла") +
theme_minimal() +
labs(title = "SVM с линейным ядром",
x = "X1", y = "X2")
# Отображаем график
print(plot)
# Печатаем количество опорных векторов
cat("Количество опорных векторов:", nrow(svm_model$SV), "\n")
# Загрузка необходимых пакетов
library(e1071)
library(ggplot2)
# Загрузка данных из файлов
train_data <- read.table("./svmdata1.txt", header = TRUE)
test_data <- read.table("./svmdata1test.txt", header = TRUE)
# Преобразуем метки классов в фактор
train_data$Color <- as.factor(train_data$Color)
test_data$Color <- as.factor(test_data$Color)
# Построение модели SVM с ядром "linear" и C=1
svm_model <- svm(Color ~ X1 + X2, data = train_data, kernel = "linear", cost = 1)
# Вывод информации о модели
summary(svm_model)
# 1) Визуализация разбиения пространства признаков на области
# Генерируем сетку для предсказания
grid <- expand.grid(X1 = seq(min(train_data$X1), max(train_data$X1), length = 200),
X2 = seq(min(train_data$X2), max(train_data$X2), length = 200))
# Прогнозирование на сетке
predictions <- predict(svm_model, newdata = grid)
# Создаем график с использованием ggplot2
plot <- ggplot(train_data, aes(x = X1, y = X2)) +
geom_point(aes(color = Color)) +
geom_raster(data = grid, aes(x = X1, y = X2, fill = predictions), interpolate = TRUE, alpha = 0.3) +
scale_fill_manual(values = c("red" = "red", "green" = "green"), name = "Класс") +
scale_color_manual(values = c("grey" = "red", "black" = "green"), name = "Класс из файла") +
theme_minimal() +
labs(title = "SVM с линейным ядром",
x = "X1", y = "X2")
# Отображаем график
print(plot)
# Печатаем количество опорных векторов
cat("Количество опорных векторов:", nrow(svm_model$SV), "\n")
# Загрузка необходимых пакетов
library(e1071)
library(ggplot2)
# Загрузка данных из файлов
train_data <- read.table("./svmdata1.txt", header = TRUE)
test_data <- read.table("./svmdata1test.txt", header = TRUE)
# Преобразуем метки классов в фактор
train_data$Color <- as.factor(train_data$Color)
test_data$Color <- as.factor(test_data$Color)
# Построение модели SVM с ядром "linear" и C=1
svm_model <- svm(Color ~ X1 + X2, data = train_data, kernel = "linear", cost = 1)
# Вывод информации о модели
summary(svm_model)
# 1) Визуализация разбиения пространства признаков на области
# Генерируем сетку для предсказания
grid <- expand.grid(X1 = seq(min(train_data$X1), max(train_data$X1), length = 200),
X2 = seq(min(train_data$X2), max(train_data$X2), length = 200))
# Прогнозирование на сетке
predictions <- predict(svm_model, newdata = grid)
# Создаем график с использованием ggplot2
plot <- ggplot(train_data, aes(x = X1, y = X2)) +
geom_point(aes(color = Color)) +
geom_raster(data = grid, aes(x = X1, y = X2, fill = predictions), interpolate = TRUE, alpha = 0.3) +
scale_fill_manual(values = c("red" = "red", "green" = "green"), name = "Класс") +
theme_minimal() +
labs(title = "SVM с линейным ядром",
x = "X1", y = "X2")
# Отображаем график
print(plot)
# Печатаем количество опорных векторов
cat("Количество опорных векторов:", nrow(svm_model$SV), "\n")
test_data$Color <- as.factor(test_data$Color)
# Загрузка необходимых пакетов
library(e1071)
library(ggplot2)
# Загрузка данных из файлов
train_data <- read.table("./svmdata1.txt", header = TRUE)
test_data <- read.table("./svmdata1test.txt", header = TRUE)
# Преобразуем метки классов в фактор
train_data$Color <- as.factor(train_data$Color)
test_data$Color <- as.factor(test_data$Color)
# Построение модели SVM с ядром "linear" и C=1
svm_model <- svm(Color ~ X1 + X2, data = train_data, kernel = "linear", cost = 1)
# Вывод информации о модели
summary(svm_model)
# 1) Визуализация разбиения пространства признаков на области
# Генерируем сетку для предсказания
grid <- expand.grid(X1 = seq(min(train_data$X1), max(train_data$X1), length = 200),
X2 = seq(min(train_data$X2), max(train_data$X2), length = 200))
# Прогнозирование на сетке
predictions <- predict(svm_model, newdata = grid)
# Создаем график с использованием ggplot2
plot <- ggplot(train_data, aes(x = X1, y = X2)) +
geom_point(aes(color = Color)) +
geom_raster(data = grid, aes(x = X1, y = X2, fill = predictions), interpolate = TRUE, alpha = 0.3) +
scale_fill_manual(values = c("red" = "red", "green" = "green"), name = "Класс") +
scale_color_manual(values = c("red" = "red", "green" = "green"), name = "Класс из файла") +
theme_minimal() +
labs(title = "SVM с линейным ядром",
x = "X1", y = "X2")
# Отображаем график
print(plot)
# Печатаем количество опорных векторов
cat("Количество опорных векторов:", nrow(svm_model$SV), "\n")
# Загрузка необходимых пакетов
library(e1071)
library(ggplot2)
# Загрузка данных из файлов
train_data <- read.table("./svmdata1.txt", header = TRUE)
test_data <- read.table("./svmdata1test.txt", header = TRUE)
# Преобразуем метки классов в фактор
train_data$Color <- as.factor(train_data$Color)
test_data$Color <- as.factor(test_data$Color)
# Построение модели SVM с ядром "linear" и C=1
svm_model <- svm(Color ~ X1 + X2, data = train_data, kernel = "linear", cost = 1)
# Вывод информации о модели
summary(svm_model)
# 1) Визуализация разбиения пространства признаков на области
# Генерируем сетку для предсказания
grid <- expand.grid(X1 = seq(min(train_data$X1), max(train_data$X1), length = 200),
X2 = seq(min(train_data$X2), max(train_data$X2), length = 200))
# Прогнозирование на сетке
predictions <- predict(svm_model, newdata = grid)
# Создаем график с использованием ggplot2
plot <- ggplot(train_data, aes(x = X1, y = X2)) +
# Точки будут другого цвета, например, черные
geom_point(aes(color = Color), size = 3) +
# Площадки для областей классов с мягким цветом
geom_raster(data = grid, aes(x = X1, y = X2, fill = predictions), interpolate = TRUE, alpha = 0.3) +
# Устанавливаем отдельные цвета для классов
scale_fill_manual(values = c("red" = "red", "green" = "green"), name = "Класс по решению SVM") +
scale_color_manual(values = c("red" = "blue", "green" = "purple"), name = "Цвет точек") +  # Цвета точек отличны от классов
theme_minimal() +
labs(title = "SVM с линейным ядром",
x = "X1", y = "X2")
# Отображаем график
print(plot)
# Печатаем количество опорных векторов
cat("Количество опорных векторов:", nrow(svm_model$SV), "\n")
# Загрузка необходимых пакетов
library(e1071)
library(ggplot2)
# Загрузка данных из файлов
train_data <- read.table("./svmdata1.txt", header = TRUE)
test_data <- read.table("./svmdata1test.txt", header = TRUE)
# Преобразуем метки классов в фактор
train_data$Color <- as.factor(train_data$Color)
test_data$Color <- as.factor(test_data$Color)
# Построение модели SVM с ядром "linear" и C=1
svm_model <- svm(Color ~ X1 + X2, data = train_data, kernel = "linear", cost = 1)
# Вывод информации о модели
summary(svm_model)
# 1) Визуализация разбиения пространства признаков на области
# Генерируем сетку для предсказания
grid <- expand.grid(X1 = seq(min(train_data$X1), max(train_data$X1), length = 200),
X2 = seq(min(train_data$X2), max(train_data$X2), length = 200))
# Прогнозирование на сетке
predictions <- predict(svm_model, newdata = grid)
# Создаем график с использованием ggplot2
plot <- ggplot(train_data, aes(x = X1, y = X2)) +
# Точки будут другого цвета, например, черные
geom_point(aes(color = Color), size = 3) +
# Площадки для областей классов с мягким цветом
geom_raster(data = grid, aes(x = X1, y = X2, fill = predictions), interpolate = TRUE, alpha = 0.3) +
# Устанавливаем отдельные цвета для классов
scale_fill_manual(values = c("red" = "red", "green" = "green"), name = "Класс по решению SVM") +
scale_color_manual(values = c("red" = "grey", "green" = "black"), name = "Цвет точек") +  # Цвета точек отличны от классов
theme_minimal() +
labs(title = "SVM с линейным ядром",
x = "X1", y = "X2")
# Отображаем график
print(plot)
# Печатаем количество опорных векторов
cat("Количество опорных векторов:", nrow(svm_model$SV), "\n")
# Подключение библиотеки
library(ggplot2)
# Загрузка данных для обучения
svmdata <- read.table("./svmdata1.txt", header = TRUE)
# Загрузка тестовых данных
svmdata_test <- read.table("./svmdata1test.txt", header = TRUE)
# Замена класса "red" на -1, а "green" на 1 в данных
svmdata$Color <- ifelse(svmdata$Color == "red", -1, ifelse(svmdata$Color == "green", 1, NA))
svmdata_test$Color <- ifelse(svmdata_test$Color == "red", -1, ifelse(svmdata_test$Color == "green", 1, NA))
# Функция вычисления экспоненты
exponent_func <- function(w, y, x1, x2) {
exp(-y * (w[1] + w[2] * x1 + w[3] * x2))
}
# Функция ошибки
error_func <- function(w, y, x1, x2, l) {
(1/l)*sum(log(1 + exponent_func(w, y, x1, x2)))
}
# Градиент
gradient <- function(w, y, x1, x2, l) {
exp_vals <- exponent_func(w, y, x1, x2)
df_w0 <- (1/l)*sum((-y * exp_vals) / (1 + exp_vals))
df_w1 <- (1/l)*sum((-y * x1 * exp_vals) / (1 + exp_vals))
df_w2 <- (1/l)*sum((-y * x2 * exp_vals) / (1 + exp_vals))
c(df_w0, df_w1, df_w2)
}
# Градиентный спуск
gradient_descent <- function(start, dataset, rate = 0.001, tol = 1e-6, max_steps = 4000000) {
w <- start
l <- nrow(dataset)
iter <- 0
repeat {
iter <- iter + 1
grad <- gradient(w, dataset$Color, dataset$X1, dataset$X2, l)
w_new <- w - rate * grad
if (sqrt(sum((w_new - w)^2)) < tol || iter >= max_steps) {
w <- w_new
break
}
w <- w_new
}
list(
w = w,
steps = iter,
error = round(error_func(w, dataset$Color, dataset$X1, dataset$X2, l), 4)
)
}
# Запуск градиентного спуска для обучения на svmdata
start_point <- c(0, 0, 0)
result <- gradient_descent(start_point, svmdata)
# Подсчет маржи для каждой точки в обучающих данных
svmdata$margin <- svmdata$Color * (result$w[1] + result$w[2] * svmdata$X1 + result$w[3] * svmdata$X2)
# Определение опорных векторов
support_vectors <- svmdata[abs(svmdata$margin - 1) < 3.745, ]
# Создаение сетки значений для X1 и X2 для визуализации
x1_range <- seq(min(svmdata$X1) - 1, max(svmdata$X1) + 1, length.out = 200)
x2_range <- seq(min(svmdata$X2) - 1, max(svmdata$X2) + 1, length.out = 200)
grid <- expand.grid(X1 = x1_range, X2 = x2_range)
# Вычисление предсказанных классов для сетки
grid$Prediction <- ifelse(result$w[1] + result$w[2] * grid$X1 + result$w[3] * grid$X2 > 0, 1, -1)
# Построение графика
ggplot() +
geom_tile(data = grid, aes(x = X1, y = X2, fill = factor(Prediction)), alpha = 0.3) +
scale_fill_manual(values = c("-1" = "red", "1" = "green"), name = "Класс") +
geom_point(data = svmdata_test, aes(x = X1, y = X2, color = factor(Color)), size = 3) +
scale_color_manual(values = c("-1" = "red", "1" = "green"), name = "Истинный класс (тест)") +
geom_abline(intercept = -result$w[1] / result$w[3], slope = -result$w[2] / result$w[3], color = "blue", size = 1, linetype = "dashed") +
labs(title = "SVM с линейной функцией ошибки", x = "X1", y = "X2") +
theme_minimal()
cat("w: ", result$w, "\nКол-во шагов: ", result$steps, "\nФункция ошибки", result$error, "\n")
cat("Количество опорных векторов:", nrow(support_vectors), "\n")
# Подключение библиотеки
library(ggplot2)
# Загрузка данных
svmdata <- read.table("./svmdata1.txt", header = TRUE)
svmdata_test <- read.table("./svmdata1test.txt", header = TRUE)
# Замена класса "red" на -1, а "green" на 1 в данных
svmdata$Color <- ifelse(svmdata$Color == "red", -1, ifelse(svmdata$Color == "green", 1, NA))
svmdata_test$Color <- ifelse(svmdata_test$Color == "red", -1, ifelse(svmdata_test$Color == "green", 1, NA))
# Функция вычисления экспоненты
exponent_func <- function(w, y, x1, x2) {
exp(-y * (w[1] + w[2] * x1 + w[3] * x2))
}
# Функция ошибки
error_func <- function(w, y, x1, x2, l) {
(1/l)*sum(exponent_func(w, y, x1, x2))
}
# Градиент
gradient <- function(w, y, x1, x2, l) {
exp_vals <- exponent_func(w, y, x1, x2)
df_w0 <- (1/l)*sum((-y * exp_vals))
df_w1 <- (1/l)*sum((-y * x1 * exp_vals))
df_w2 <- (1/l)*sum((-y * x2 * exp_vals))
c(df_w0, df_w1, df_w2)
}
# Градиентный спуск
gradient_descent <- function(start, dataset, rate = 0.001, tol = 1e-6, max_steps = 4000000) {
w <- start
l <- nrow(dataset)
iter <- 0
repeat {
iter <- iter + 1
grad <- gradient(w, dataset$Color, dataset$X1, dataset$X2, l)
w_new <- w - rate * grad
if (sqrt(sum((w_new - w)^2)) < tol || iter >= max_steps) {
w <- w_new
break
}
w <- w_new
}
list(
w = w,
steps = iter,
error = round(error_func(w, dataset$Color, dataset$X1, dataset$X2, l), 4)
)
}
# Запуск градиентного спуска для обучения на svmdata
start_point <- c(0, 0, 0)
result <- gradient_descent(start_point, svmdata)
# Подсчет маржи для каждой точки в обучающих данных
svmdata$margin <- svmdata$Color * (result$w[1] + result$w[2] * svmdata$X1 + result$w[3] * svmdata$X2)
# Определение опорных векторов
support_vectors <- svmdata[abs(svmdata$margin - 1) < 3.75, ]
# Создание сетки значений для X1 и X2 для визуализации
x1_range <- seq(min(svmdata$X1) - 1, max(svmdata$X1) + 1, length.out = 200)
x2_range <- seq(min(svmdata$X2) - 1, max(svmdata$X2) + 1, length.out = 200)
grid <- expand.grid(X1 = x1_range, X2 = x2_range)
# Вычисление предсказанных класс для сетки
grid$Prediction <- ifelse(result$w[1] + result$w[2] * grid$X1 + result$w[3] * grid$X2 > 0, 1, -1)
# Отображение результата
ggplot() +
geom_tile(data = grid, aes(x = X1, y = X2, fill = factor(Prediction)), alpha = 0.3) +
scale_fill_manual(values = c("-1" = "red", "1" = "green"), name = "Класс") +
geom_point(data = svmdata_test, aes(x = X1, y = X2, color = factor(Color)), size = 3) +
scale_color_manual(values = c("-1" = "red", "1" = "green"), name = "Истинный класс (тест)") +
geom_abline(intercept = -result$w[1] / result$w[3], slope = -result$w[2] / result$w[3], color = "blue", size = 1, linetype = "dashed") +
labs(title = "SVM с экспоненциальной функцией ошибки", x = "X1", y = "X2") +
theme_minimal()
cat("w: ", result$w, "\nКол-во шагов: ", result$steps, "\nФункция ошибки", result$error, "\n")
cat("Количество опорных векторов:", nrow(support_vectors), "\n")
# Загрузка необходимых пакетов
library(e1071)
library(ggplot2)
# Загрузка данных из файлов
train_data <- read.table("./svmdata1.txt", header = TRUE)
test_data <- read.table("./svmdata1test.txt", header = TRUE)
# Преобразуем метки классов в фактор
train_data$Color <- as.factor(train_data$Color)
test_data$Color <- as.factor(test_data$Color)
# Построение модели SVM с ядром "linear" и C=1
svm_model <- svm(Color ~ X1 + X2, data = train_data, kernel = "linear", cost = 1)
# Создание сетки для предсказания
grid <- expand.grid(X1 = seq(min(train_data$X1), max(train_data$X1), length = 200),
X2 = seq(min(train_data$X2), max(train_data$X2), length = 200))
# Прогнозирование на сетке
predictions <- predict(svm_model, newdata = grid)
# Создание графика с использованием ggplot2
plot <- ggplot(train_data, aes(x = X1, y = X2)) +
geom_point(aes(color = Color), size = 3) +
geom_raster(data = grid, aes(x = X1, y = X2, fill = predictions), interpolate = TRUE, alpha = 0.3) +
scale_fill_manual(values = c("red" = "red", "green" = "green"), name = "Класс по решению SVM") +
scale_color_manual(values = c("red" = "grey", "green" = "black"), name = "Цвет точек") +  # Цвета точек отличны от классов
theme_minimal() +
labs(title = "SVM с линейным ядром",
x = "X1", y = "X2")
print(plot)
cat("Количество опорных векторов:", nrow(svm_model$SV), "\n")
